#+TITLE: Fractional tri-factorial experiment design and statistical estimates application

(you can find full source at =src/ffe.py=, MIT license)

Available on other languages:
- [[file:README.org][English]]
- [[file:README.ua.org][Українська]]

** Task description
Design a fractional tri-factorial experiment, find linear regression (the model) and
apply statistical estimates (Cochran's C test, Student's t test, Fisher's F test)
to find the model adequate to the original object.

** Initial conditions
For example, let's define the following factors bounds and their quantity:
#+BEGIN_SRC python :session ffe
x_bounds = [[1, 1], [10, 60], [15, 50], [15, 20]]
factors = len(x_bounds)
#+END_SRC

For convenience, we add null-factor to the three main factors, which is always equal to one.
Design of the fractional experiment implies that we use only part of a full experiment (a half):
#+BEGIN_SRC python :session ffe
experiments = 4
#+END_SRC

Also, we define the repeats number of the same factors combination and confidence probability
for statistical estimates:
#+BEGIN_SRC python :session ffe
samples = 2
confidence_prob = 0.9
#+END_SRC

For experimentally aquired values we take randomly generated numbers in arbitrarily
defined bounds:
#+BEGIN_SRC python :session ffe
import random
import numpy as np

y_bounds = [
    int(200 + np.mean([min(x_bounds[i]) for i in range(1, factors)])),
    int(300 + np.mean([max(x_bounds[i]) for i in range(1, factors)])),
]
y = [
        [random.randint(min(y_bounds), max(y_bounds)) for i in range(samples)]
        for j in range(experiments)
    ]
#+END_SRC

** Experiment plan
Let's fill experiment matrix with encoded factors values and response function values. From possible combinations
we choose only those, that comply with full plan properties (symmetrical, normed, orthogonal).
For encoded values matrix (=xn=) we create corresponding decoded matrix =x=:
#+BEGIN_SRC python :session ffe
import itertools

combinations = list(itertools.product([-1, 1], repeat=4))
xn = [combinations[8], combinations[11], combinations[13], combinations[14]]
x = [
    [
        min(x_bounds[j]) if xn[i][j] < 0 else max(x_bounds[j])
        for j in range(len(x_bounds))
    ]
    for i in range(len(xn))
]
#+END_SRC

For output formatting we use =prettytable= module. Let's define function to create experiment matrix:
#+BEGIN_SRC python :results output org :session ffe :exports both
from prettytable import PrettyTable

def create_matrix():
    table = PrettyTable()
    table_head = ["Experiment #"]
    for i in range(factors):
        table_head.append(f"x{i}")
    for i in range(samples):
        table_head.append(f"y{i+1}")
    table.field_names = table_head
    for i in range(experiments):
        table.add_row([i + 1, *xn[i], *y[i]])
    return table

matrix = create_matrix()
print(matrix)
#+END_SRC

#+RESULTS:
#+begin_src org
+--------------+----+----+----+----+-----+-----+
| Experiment # | x0 | x1 | x2 | x3 |  y1 |  y2 |
+--------------+----+----+----+----+-----+-----+
|      1       | 1  | -1 | -1 | -1 | 285 | 287 |
|      2       | 1  | -1 | 1  | 1  | 312 | 219 |
|      3       | 1  | 1  | -1 | 1  | 286 | 336 |
|      4       | 1  | 1  | 1  | -1 | 284 | 333 |
+--------------+----+----+----+----+-----+-----+
#+end_src

** Statistical estimates of the results
For critical test values we use =scipy= module:
#+BEGIN_SRC python :session ffe
import scipy
from scipy.stats import f
from scipy.stats import t

def f_critical(prob, f1, f2):
    return scipy.stats.f.ppf(prob, f1, f2)

def t_critical(prob, df):
    return scipy.stats.t.ppf(prob, df)

def c_critical(prob, f1, f2):
    return 1 / (1 + (f2 - 1) / scipy.stats.f.ppf(1 - (1-prob)/f2, f1, (f2 - 1)*f1) )
#+END_SRC

*** Cochran's C test
To test variance homogeneity of response function by rows, we use Cochran's C test. Estimate of Cochran's test
is calculated as a ratio of maximal variance to the variances sum:
#+BEGIN_SRC python :session ffe
s2_y = [np.var(y[i]) for i in range(experiments)]
stat_c = max(s2_y) / sum(s2_y)
#+END_SRC

Let's calculate the critical value and compare it to the estimate:
#+BEGIN_SRC python :results output org :session ffe :exports both
crit_c = c_critical(confidence_prob, samples-1, experiments)

print(f"Calculated C statistics: {round(stat_c, 3)}")
print(
    f"Critical C for confidence probability of {confidence_prob}: {round(crit_c, 3)}"
)
#+END_SRC

#+RESULTS:
#+begin_src org
Calculated C statistics: 0.638
Critical C for confidence probability of 0.9: 0.853
#+end_src

The estimate is lower than critical value, hence variances are homogeneous. But what to do, if they
are not homogeneous? To prevent this, we envelop response generation code with =while= loop,
and on every negative result increase sample rate by one:
#+BEGIN_SRC python :results output org :session ffe :exports both
while True:
    y = [
        [random.randint(min(y_bounds), max(y_bounds)) for i in range(samples)]
        for j in range(experiments)
    ]
    matrix = create_matrix()
    s2_y = [np.var(y[i]) for i in range(experiments)]
    stat_c = max(s2_y) / sum(s2_y)
    crit_c = c_critical(confidence_prob, samples - 1, experiments)
    print(matrix)
    print(f"Calculated C statistics: {round(stat_c, 3)}")
    print(
        f"Critical C for confidence probability of {confidence_prob}: {round(crit_c, 3)}"
    )
    if stat_c < crit_c:
        print("Variances are equal.")
        break
    print("Variances are not equal. Increasing sample size...")
    samples += 1
#+END_SRC

#+RESULTS:
#+begin_src org
+--------------+----+----+----+----+-----+-----+
| Experiment # | x0 | x1 | x2 | x3 |  y1 |  y2 |
+--------------+----+----+----+----+-----+-----+
|      1       | 1  | -1 | -1 | -1 | 251 | 272 |
|      2       | 1  | -1 | 1  | 1  | 280 | 304 |
|      3       | 1  | 1  | -1 | 1  | 314 | 293 |
|      4       | 1  | 1  | 1  | -1 | 341 | 221 |
+--------------+----+----+----+----+-----+-----+
Calculated C statistics: 0.908
Critical C for confidence probability of 0.9: 0.853
Variances are not equal. Increasing sample size...
+--------------+----+----+----+----+-----+-----+-----+
| Experiment # | x0 | x1 | x2 | x3 |  y1 |  y2 |  y3 |
+--------------+----+----+----+----+-----+-----+-----+
|      1       | 1  | -1 | -1 | -1 | 234 | 231 | 296 |
|      2       | 1  | -1 | 1  | 1  | 337 | 225 | 275 |
|      3       | 1  | 1  | -1 | 1  | 322 | 270 | 238 |
|      4       | 1  | 1  | 1  | -1 | 275 | 294 | 302 |
+--------------+----+----+----+----+-----+-----+-----+
Calculated C statistics: 0.486
Critical C for confidence probability of 0.9: 0.708
Variances are equal.
#+end_src

*** Regression equation and Student's t test
Let's calculate response mean values by rows:
#+BEGIN_SRC python :session ffe
my = [np.mean(y[i]) for i in range(len(y))]
#+END_SRC

Let's sort encoded factors values by columns and calculate regression coefficients for
encoded values (also called regression coeficients estimates):
#+BEGIN_SRC python :session ffe
xn_col = np.array(list(zip(*xn)))
beta = [np.mean(my * xn_col[i]) for i in range(experiments)]
#+END_SRC

To test the results we can calculate function value, using found coefficients and encoded factors.
Calculation results must be equal to response mean values:
#+BEGIN_SRC python :results output org :session ffe :exports both
yn = [sum(beta * np.array(xn[i])) for i in range(experiments)]

print(f"Means: {[round(my[i], 3) for i in range(experiments)]}")
print(f"Calculated function: {[round(yn[i], 3) for i in range(experiments)]}")
#+END_SRC

#+RESULTS:
#+begin_src org
Means: [253.667, 279.0, 276.667, 290.333]
Calculated function: [253.667, 279.0, 276.667, 290.333]
#+end_src

We decode the coefficients, to find regular linear regression for decoded factors:
#+BEGIN_SRC python :session ffe
delta_x = [abs(x_bounds[i][0] - x_bounds[i][1]) / 2 for i in range(len(x_bounds))]
x0 = [(x_bounds[i][0] + x_bounds[i][1]) / 2 for i in range(len(x_bounds))]
b = [beta[0] - sum(beta[i] * x0[i] / delta_x[i] for i in range(1, factors))]
b.extend([beta[i] / delta_x[i] for i in range(1, factors)])
#+END_SRC

Now we conduct Student's t test to find significant regression coefficients.
Let's find general recreation estimate, coefficients variance estimate and
Student's estimate:
#+BEGIN_SRC python :session ffe
s2_b = sum(s2_y) / len(s2_y)
s_beta = np.sqrt(s2_b / samples / experiments)
stat_t = [abs(beta[i]) / s_beta for i in range(factors)]
#+END_SRC

Let's calculate the critical value and compare it to the estimate:
#+BEGIN_SRC python :results output org :session ffe :exports both
crit_t = t_critical(confidence_prob, (samples-1)*experiments)

print(f"Calculated t statistics: {[round(stat_t[i], 3) for i in range(len(stat_t))]}")
print(f"Critical t for confidence probability of {confidence_prob}: {round(crit_t, 3)}")
#+END_SRC

#+RESULTS:
#+begin_src org
Calculated t statistics: [28.97, 0.904, 1.027, 0.307]
Critical t for confidence probability of 0.9: 1.397
#+end_src

As we can see, not all coefficients pass the test (=stat_t[i] > crit_t=).
Decoded coefficients, that don't pass the test we equate to zero, and
number of significant coefficients we write to a variable:
#+BEGIN_SRC python :results output org :session ffe :exports both
significant_coeffs = 0
for i in range(len(stat_t)):
    if stat_t[i] < crit_t:
        b[i] = 0
        significant_coeffs += 1

print(f"Regression coefficients: {[round(b[i], 3) for i in range(len(b))]}")
#+END_SRC

#+RESULTS:
#+begin_src org
Regression coefficients: [224.376, 0, 0, 0]
#+end_src

*** Fisher's F test
First, we calculate function values for found regression equation:
#+BEGIN_SRC python :results output org :session ffe :exports both
y_calc = [sum((b * np.array(x))[i]) for i in range(experiments)]

print(
    f"Calculated values of model: {[round(y_calc[i], 3) for i in range(len(y_calc))]}"
)
#+END_SRC

#+RESULTS:
#+begin_src org
Calculated values of model: [224.376, 224.376, 224.376, 224.376]
#+end_src

Let's calculate adequate model variance and find Fisher's estimate, which equals to ratio of
adequate model variance to recreation variance:
#+BEGIN_SRC python :session ffe
s2_adeq = (
    samples
    / (experiments - significant_coeffs)
    * sum([(y_calc[i] - my[i]) ** 2 for i in range(experiments)])
)
stat_f = s2_adeq / s2_b
#+END_SRC

Let's calculate the critical value and compare it to the estimate:
#+BEGIN_SRC python :results output org :session ffe :exports both
crit_f = f_critical(confidence_prob, (samples-1)*experiments, experiments - significant_coeffs)

print(f"Calculated F statistics: {round(stat_f, 3)}")
print(f"Critical F for confidence probability of {confidence_prob}: {round(crit_f, 3)}")
#+END_SRC

#+RESULTS:
#+begin_src org
Calculated F statistics: 30.332
Critical F for confidence probability of 0.9: 59.439
#+end_src

The estimate is lower than critical value, thus the model is adequate to the original.
